#!/usr/bin/env python3
"""
Streamlit app for PDF fixture table extraction using Gemini
"""

import streamlit as st
import pandas as pd
import pdfplumber
import google.generativeai as genai
import json
import re
import os
from pathlib import Path
from typing import List, Dict, Any
from dotenv import load_dotenv
import tempfile
import concurrent.futures
import threading
from io import BytesIO

# Load environment variables
load_dotenv()

# Page config
st.set_page_config(
    page_title="å»ºå…·è¡¨æŠ½å‡ºã‚¢ãƒ—ãƒª",
    page_icon="ğŸ—ï¸",
    layout="wide"
)

class LLMFixtureParser:
    def __init__(self, api_key=None):
        # Geminiè¨­å®š
        api_key = api_key or os.getenv('GEMINI_API_KEY')
        if api_key:
            genai.configure(api_key=api_key)
            self.model = genai.GenerativeModel('gemini-2.5-flash')
        else:
            raise ValueError("GEMINI_API_KEYç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")

        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
        self.system_prompt = """ã‚ãªãŸã¯å»ºç¯‰å›³é¢ã®å»ºå…·è¡¨ã‚’è§£æã™ã‚‹å°‚é–€å®¶ã§ã™ã€‚
ä¸ãˆã‚‰ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰å»ºå…·æƒ…å ±ã‚’æŠ½å‡ºã—ã€æ§‹é€ åŒ–ã•ã‚ŒãŸJSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

å»ºå…·è¡¨ã®å„é …ç›®ã¯ä»¥ä¸‹ã®æƒ…å ±ã‚’å«ã¿ã¾ã™ï¼š
- è¨˜å·: å»ºå…·ã®è­˜åˆ¥è¨˜å·ï¼ˆä¾‹: SS-3, AD-1ï¼‰ å¿…ãš ** å¤§æ–‡å­—è‹±å­—å¤§æ–‡å­—è‹±å­—-æ•°å­—ã®å½¢å¼ ** ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
- æ•°é‡: å€‹æ•°
- å®¤å: è¨­ç½®å ´æ‰€
- å‹å¼: å»ºå…·ã®å‹å¼ã‚„ä»•æ§˜ã€
- è¦‹è¾¼ï¼šè¦‹è¾¼å¯¸æ³•
- å§¿å›³: ç©ºã§å‡ºåŠ›ã—ã¦ãã ã•ã„
- ä»•ä¸Šã’: è¡¨é¢ä»•ä¸Šã’
- ã‚¬ãƒ©ã‚¹: ã‚¬ãƒ©ã‚¹ä»•æ§˜
- ä»˜å±é‡‘ç‰©: ä»˜å±ã™ã‚‹é‡‘ç‰©
- å‚™è€ƒ: ãƒ¡ãƒ¼ã‚«ãƒ¼åã‚„ãã®ä»–ã®æƒ…å ±

- *-*ã¯ç©ºã§å‡ºåŠ›ã—ã¦ãã ã•ã„
- è¦‹è¾¼ã¯*ç©º*ã‹*æ•°å€¤ã¨å˜ä½*ã§ã‚ã‚Šã€ä¸€ã¤ã—ã‹ã‚ã‚Šã¾ã›ã‚“ã€‚å§¿å›³ã§ã®æ•°å€¤ã‚’æ··åŒã—ãªã„ã‚ˆã†ã«æ°—ã‚’ä»˜ã‘ã¦ãã ã•ã„ã€‚
"""

        self.extract_prompt_template = """ä»¥ä¸‹ã®å»ºå…·è¡¨ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ã€ã™ã¹ã¦ã®å»ºå…·æƒ…å ±ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚

ãƒ†ã‚­ã‚¹ãƒˆ:
{text}

ä»¥ä¸‹ã®JSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼š
{{
    "fixtures": [
        {{
            "è¨˜å·": "SS-3",
            "æ•°é‡": 2,
            "å®¤å": "ï¼‘ï¼¦ï¼šç ”ä¿®å®Ÿç¿’å®¤",
            "å‹å¼": "é›»å‹•ã‚·ãƒ£ãƒƒã‚¿ãƒ¼",
            "è¦‹è¾¼": "",
            "å§¿å›³": "",
            "ä»•ä¸Šã’": "",
            "ã‚¬ãƒ©ã‚¹": "",
            "ä»˜å±é‡‘ç‰©": "æ¨™æº–é‡‘ç‰©ä¸€å¼",
            "å‚™è€ƒ": "æ–‡åŒ–ã‚·ãƒ£ãƒƒã‚¿ãƒ¼ï¼šå¾¡å‰æ§˜"
        }},
        ...
    ]
}}
"""

    def extract_with_gemini(self, text: str) -> List[Dict[str, Any]]:
        """Gemini APIã‚’ä½¿ç”¨ã—ã¦æŠ½å‡º"""
        try:
            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’çµåˆ
            prompt = self.system_prompt + "\n\n" + self.extract_prompt_template.format(text=text)
            
            response = self.model.generate_content(prompt)
            result_text = response.text

            # JSONéƒ¨åˆ†ã‚’æŠ½å‡º
            json_match = re.search(r'\{[\s\S]*\}', result_text)
            if json_match:
                result = json.loads(json_match.group())
                return result.get('fixtures', [])

        except Exception as e:
            st.error(f"âš ï¸ Gemini API ã‚¨ãƒ©ãƒ¼: {e}")

        return []

    def process_pdf_page(self, page, page_num: int) -> List[Dict[str, Any]]:
        """å˜ä¸€ãƒšãƒ¼ã‚¸ã‚’å‡¦ç†"""
        # ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡º
        text = page.extract_text()
        if not text:
            return []

        # å»ºå…·è¡¨ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’è­˜åˆ¥
        if 'å»ºå…·è¡¨' in text or 'è¨˜å·' in text:
            # Geminiã§æŠ½å‡º
            fixtures = self.extract_with_gemini(text)
            return fixtures
        
        return []

    def validate_and_clean(self, fixtures: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """æŠ½å‡ºçµæœã®æ¤œè¨¼ã¨ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°"""
        cleaned = []

        for fixture in fixtures:
            # è¨˜å·ã®æ¤œè¨¼
            if not fixture.get('è¨˜å·'):
                continue

            # æ•°é‡ã®æ¤œè¨¼
            try:
                fixture['æ•°é‡'] = int(fixture.get('æ•°é‡', 1))
            except:
                fixture['æ•°é‡'] = 1

            # ç©ºæ–‡å­—åˆ—ã®å‡¦ç†
            for key in fixture:
                if fixture[key] == '-' or fixture[key] == 'ï¼':
                    fixture[key] = ''
                elif isinstance(fixture[key], str):
                    fixture[key] = fixture[key].strip()

            cleaned.append(fixture)

        return cleaned

def main():
    st.title("ğŸ—ï¸ å»ºå…·è¡¨æŠ½å‡ºã‚¢ãƒ—ãƒª")
    st.markdown("PDFã‹ã‚‰å»ºå…·è¡¨ã‚’è‡ªå‹•æŠ½å‡ºã—ã¾ã™")

    # Initialize session state
    if 'results' not in st.session_state:
        st.session_state.results = {}

    # Get specific PDF file
    pdf_file = Path("data/image.pdf")
    
    # Alternative: Use a fixed version if available
    # pdf_file = Path("data/image_fixed.pdf") if Path("data/image_fixed.pdf").exists() else Path("data/image.pdf")
    
    if not pdf_file.exists():
        st.error("data/image.pdf ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return

    # Main area for PDF processing
    st.info(f"ğŸ“„ å‡¦ç†å¯¾è±¡: {pdf_file.name}")
    
    if st.button("ğŸ” æŠ½å‡ºé–‹å§‹", type="primary", use_container_width=True):
        # Initialize parser
        try:
            parser = LLMFixtureParser()
            
            # Process PDF
            all_fixtures = []
            page_results = {}
            progress_container = st.container()
            
            # Check if screenshots exist
            screenshot_dir = Path("data/pdf_screenshots")
            use_screenshots = screenshot_dir.exists() and len(list(screenshot_dir.glob("page_*.png"))) > 0
            
            if use_screenshots:
                # Use pre-made screenshots
                st.info("ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã‚’ä½¿ç”¨ã—ã¾ã™...")
                progress_bar = st.progress(0, text="ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã‚’èª­ã¿è¾¼ã¿ä¸­...")
                
                # Get all screenshot files
                screenshot_files = sorted(screenshot_dir.glob("page_*.png"))
                total_pages = len(screenshot_files)
                
                # Extract text from PDF using pdfplumber
                page_texts = []
                with pdfplumber.open(str(pdf_file)) as pdf:
                    for page in pdf.pages:
                        text = page.extract_text()
                        page_texts.append(text)
                
                # Prepare page data with screenshots
                page_data = []
                for i, (screenshot_file, text) in enumerate(zip(screenshot_files, page_texts)):
                    page_num = i + 1
                    progress_bar.progress(page_num / total_pages, text=f"ãƒšãƒ¼ã‚¸ {page_num}/{total_pages} ã‚’æº–å‚™ä¸­...")
                    
                    # Read screenshot
                    with open(screenshot_file, 'rb') as f:
                        img_buffer = BytesIO(f.read())
                        img_buffer.seek(0)
                    
                    page_data.append({
                        'page_num': page_num,
                        'image_buffer': img_buffer,  # Screenshot buffer
                        'text': text,
                        'has_fixtures': 'å»ºå…·è¡¨' in text or 'è¨˜å·' in text if text else False
                    })
            else:
                # Fallback to pdf2image conversion
                st.warning("ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚pdf2imageã§å¤‰æ›ã—ã¾ã™...")
                progress_bar = st.progress(0, text="PDFã‚’PNGç”»åƒã«å¤‰æ›ä¸­...")
                
                try:
                    from pdf2image import convert_from_path
                    
                    # Convert with optimized settings
                    png_images = convert_from_path(
                        pdf_path=str(pdf_file), 
                        dpi=200,
                        fmt='png',
                        thread_count=1,
                        use_pdftocairo=False,
                        strict=False
                    )
                    
                    total_pages = len(png_images)
                    
                    # Save PNG images in memory
                    png_buffers = []
                    for i, img in enumerate(png_images):
                        progress_bar.progress((i + 1) / total_pages, text=f"PNGç”»åƒã‚’ä¿å­˜ä¸­... {i + 1}/{total_pages}")
                        buffer = BytesIO()
                        img.save(buffer, format='PNG', optimize=True, quality=95)
                        buffer.seek(0)
                        png_buffers.append(buffer)
                    
                    # Extract text from PDF
                    page_texts = []
                    with pdfplumber.open(str(pdf_file)) as pdf:
                        for page in pdf.pages:
                            text = page.extract_text()
                            page_texts.append(text)
                    
                    # Prepare page data
                    page_data = []
                    for page_num, (png_buffer, text) in enumerate(zip(png_buffers, page_texts), 1):
                        page_data.append({
                            'page_num': page_num,
                            'image_buffer': png_buffer,
                            'text': text,
                            'has_fixtures': 'å»ºå…·è¡¨' in text or 'è¨˜å·' in text if text else False
                        })
                    
                except Exception as e:
                    st.error(f"PDFå¤‰æ›ã‚¨ãƒ©ãƒ¼: {e}")
                    st.info("data/pdf_screenshots/page_1.png, page_2.png... ã¨ã—ã¦ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã‚’ä¿å­˜ã—ã¦ãã ã•ã„")
                    return
            
            # Display page images first
            with progress_container:
                st.subheader("å‡¦ç†çŠ¶æ³")
                
                # Create placeholders for each page
                page_containers = {}
                for page_info in page_data:
                    page_num = page_info['page_num']
                    
                    # Create columns for page image and results
                    col1, col2 = st.columns([1, 1])
                    
                    with col1:
                        st.markdown(f"**ãƒšãƒ¼ã‚¸ {page_num}:**")
                        if 'image_buffer' in page_info and page_info['image_buffer']:
                            # Display PNG image from buffer
                            st.image(page_info['image_buffer'], caption=f"Page {page_num}", use_container_width=True)
                        else:
                            st.info("ãƒšãƒ¼ã‚¸ç”»åƒã‚’è¡¨ç¤ºã§ãã¾ã›ã‚“")
                    
                    with col2:
                        st.markdown("**æŠ½å‡ºçµæœ:**")
                        # Create placeholder for results
                        page_containers[page_num] = st.container()
                        with page_containers[page_num]:
                            if page_info['has_fixtures']:
                                st.info("ğŸ”„ å‡¦ç†å¾…æ©Ÿä¸­...")
                            else:
                                st.info("ã“ã®ãƒšãƒ¼ã‚¸ã«å»ºå…·è¡¨ã¯ã‚ã‚Šã¾ã›ã‚“")
                    
                    st.divider()
            
            # Process pages with Gemini API in parallel
            progress_bar.progress(0, text="å»ºå…·æƒ…å ±ã‚’æŠ½å‡ºä¸­...")
            
            # Process pages with fixtures
            pages_with_fixtures = [p for p in page_data if p['has_fixtures']]
            total_to_process = len(pages_with_fixtures)
            
            # First, send all requests to Gemini in parallel
            with st.spinner(f"Gemini APIã«{total_to_process}ãƒšãƒ¼ã‚¸åˆ†ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é€ä¿¡ä¸­..."):
                with concurrent.futures.ThreadPoolExecutor(max_workers=8) as executor:
                    # Submit all extraction tasks
                    future_to_page = {}
                    for page_info in pages_with_fixtures:
                        future = executor.submit(parser.extract_with_gemini, page_info['text'])
                        future_to_page[future] = page_info['page_num']
                    
                    # Collect results as they complete
                    api_results = {}
                    completed = 0
                    
                    for future in concurrent.futures.as_completed(future_to_page):
                        page_num = future_to_page[future]
                        try:
                            result = future.result()
                            api_results[page_num] = result
                        except Exception as e:
                            api_results[page_num] = {'error': str(e)}
                        
                        completed += 1
                        progress_bar.progress(completed / total_to_process, 
                                            text=f"APIå‡¦ç†å®Œäº†: {completed}/{total_to_process} ãƒšãƒ¼ã‚¸")
            
            # Then update UI sequentially
            st.info("UI ã‚’æ›´æ–°ä¸­...")
            for page_info in pages_with_fixtures:
                page_num = page_info['page_num']
                
                # Get the result from API calls
                result = api_results.get(page_num, None)
                
                # Update the placeholder with results
                with page_containers[page_num]:
                    # Clear the waiting message
                    page_containers[page_num].empty()
                    
                    if isinstance(result, dict) and 'error' in result:
                        st.error(f"ã‚¨ãƒ©ãƒ¼: {result['error']}")
                    elif result:
                        # Display extracted data
                        fixtures = result
                        page_results[page_num] = fixtures
                        all_fixtures.extend(fixtures)
                        
                        for i, fixture in enumerate(fixtures):
                            with st.expander(f"å»ºå…· {i+1}: {fixture.get('è¨˜å·', 'N/A')}", expanded=False):
                                for key, value in fixture.items():
                                    st.text(f"{key}: {value}")
                    else:
                        st.warning("å»ºå…·æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            
            # Clean results
            all_fixtures = parser.validate_and_clean(all_fixtures)
            
            # Store results
            st.session_state.results[pdf_file.name] = all_fixtures
            
            st.success("âœ… æŠ½å‡ºå®Œäº†ï¼")
            st.rerun()
            
        except Exception as e:
            st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

    # Display results at the bottom
    if st.session_state.results:
        st.markdown("---")
        st.header("ğŸ“Š æŠ½å‡ºçµæœ")
        
        for pdf_name, fixtures in st.session_state.results.items():
            if fixtures:
                # Convert to DataFrame
                df = pd.DataFrame(fixtures)
                
                # Display metrics
                col1, col2 = st.columns(2)
                with col1:
                    st.metric("å»ºå…·æ•°", f"{len(fixtures)} ä»¶")
                with col2:
                    st.metric("ç·æ•°é‡", f"{sum(f.get('æ•°é‡', 0) for f in fixtures)} å€‹")
                
                # Display table
                st.dataframe(df, use_container_width=True)
                
                # Download button for CSV
                csv = df.to_csv(index=False, encoding='utf-8-sig')
                st.download_button(
                    label="ğŸ“¥ CSVã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=csv,
                    file_name=f"{pdf_name.replace('.pdf', '')}_fixtures.csv",
                    mime='text/csv'
                )
                
                # Calculate accuracy against answer.csv
                st.markdown("---")
                st.subheader("ğŸ¯ æ­£è§£ç‡ã®è©•ä¾¡")
                
                try:
                    # Load answer.csv
                    answer_df = pd.read_csv("data/answer.csv")
                    
                    # Calculate accuracy
                    total_correct = 0
                    total_items = len(answer_df)
                    
                    # Create comparison dataframe
                    comparison_data = []
                    
                    for _, answer_row in answer_df.iterrows():
                        symbol = answer_row['è¨˜å·']
                        
                        # Find matching row in extracted data
                        extracted_rows = df[df['è¨˜å·'] == symbol]
                        
                        if not extracted_rows.empty:
                            extracted_row = extracted_rows.iloc[0]
                            
                            # Compare each field
                            field_results = {}
                            field_results['è¨˜å·'] = symbol
                            
                            # Check each field
                            is_correct = True
                            for field in ['æ•°é‡', 'å®¤å', 'å‹å¼', 'è¦‹è¾¼', 'ä»•ä¸Šã’', 'ã‚¬ãƒ©ã‚¹', 'ä»˜å±é‡‘ç‰©', 'å‚™è€ƒ']:
                                answer_val = str(answer_row.get(field, '')).strip()
                                extracted_val = str(extracted_row.get(field, '')).strip()
                                
                                # Handle empty values
                                if answer_val in ['nan', 'NaN', '']:
                                    answer_val = ''
                                if extracted_val in ['nan', 'NaN', '']:
                                    extracted_val = ''
                                
                                # Compare
                                if answer_val == extracted_val:
                                    field_results[field] = 'âœ…'
                                else:
                                    field_results[field] = f'âŒ (æ­£è§£: {answer_val}, æŠ½å‡º: {extracted_val})'
                                    is_correct = False
                            
                            if is_correct:
                                total_correct += 1
                            
                            comparison_data.append(field_results)
                        else:
                            # Missing item
                            comparison_data.append({
                                'è¨˜å·': symbol,
                                'æ•°é‡': 'âŒ (æœªæŠ½å‡º)',
                                'å®¤å': 'âŒ (æœªæŠ½å‡º)',
                                'å‹å¼': 'âŒ (æœªæŠ½å‡º)',
                                'è¦‹è¾¼': 'âŒ (æœªæŠ½å‡º)',
                                'ä»•ä¸Šã’': 'âŒ (æœªæŠ½å‡º)',
                                'ã‚¬ãƒ©ã‚¹': 'âŒ (æœªæŠ½å‡º)',
                                'ä»˜å±é‡‘ç‰©': 'âŒ (æœªæŠ½å‡º)',
                                'å‚™è€ƒ': 'âŒ (æœªæŠ½å‡º)'
                            })
                    
                    # Calculate and display accuracy
                    accuracy = (total_correct / total_items) * 100 if total_items > 0 else 0
                    
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("æ­£è§£æ•°", f"{total_correct} / {total_items}")
                    with col2:
                        st.metric("æ­£è§£ç‡", f"{accuracy:.1f}%")
                    with col3:
                        st.metric("æŠ½å‡ºæ•°", f"{len(df)} ä»¶")
                    
                    # Show detailed comparison
                    with st.expander("è©³ç´°ãªæ¯”è¼ƒçµæœ", expanded=False):
                        comparison_df = pd.DataFrame(comparison_data)
                        st.dataframe(comparison_df, use_container_width=True)
                        
                        # Download comparison CSV
                        comparison_csv = comparison_df.to_csv(index=False, encoding='utf-8-sig')
                        st.download_button(
                            label="ğŸ“¥ æ¯”è¼ƒçµæœã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                            data=comparison_csv,
                            file_name="comparison_results.csv",
                            mime='text/csv'
                        )
                    
                except Exception as e:
                    st.error(f"æ­£è§£ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
                
            else:
                st.info("å»ºå…·è¡¨ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")

if __name__ == "__main__":
    main()